{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/introyt/trainingyt.html\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress  Ankle Boot  Trouser  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3812, 0.8325, 0.5014, 0.5250, 0.7565, 0.9984, 0.8690, 0.4000, 0.9367,\n",
      "         0.5663],\n",
      "        [0.1997, 0.1567, 0.8684, 0.2242, 0.2641, 0.1148, 0.1836, 0.6979, 0.4555,\n",
      "         0.0959],\n",
      "        [0.1528, 0.7750, 0.2675, 0.9650, 0.4896, 0.6556, 0.8146, 0.7569, 0.4352,\n",
      "         0.6952],\n",
      "        [0.4049, 0.5514, 0.1578, 0.9423, 0.7391, 0.4806, 0.1283, 0.9318, 0.1162,\n",
      "         0.5707]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.1502976417541504\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 2.106741943359375\n",
      "  batch 2000 loss: 0.913252208326012\n",
      "  batch 3000 loss: 0.7347511173645035\n",
      "  batch 4000 loss: 0.6311285689226351\n",
      "  batch 5000 loss: 0.6016184562965063\n",
      "  batch 6000 loss: 0.5503495581073221\n",
      "  batch 7000 loss: 0.5082738910954213\n",
      "  batch 8000 loss: 0.5127267408486222\n",
      "  batch 9000 loss: 0.5037903176846449\n",
      "  batch 10000 loss: 0.46668173057679085\n",
      "  batch 11000 loss: 0.4800563316164771\n",
      "  batch 12000 loss: 0.4613809284810559\n",
      "  batch 13000 loss: 0.4730755400476046\n",
      "  batch 14000 loss: 0.41612718265014703\n",
      "  batch 15000 loss: 0.42135816100193185\n",
      "LOSS train 0.42135816100193185 valid 0.42685702443122864\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.4192455394282006\n",
      "  batch 2000 loss: 0.37006641705031507\n",
      "  batch 3000 loss: 0.38780553507152943\n",
      "  batch 4000 loss: 0.37869710429984843\n",
      "  batch 5000 loss: 0.39624429008050355\n",
      "  batch 6000 loss: 0.3819613498459075\n",
      "  batch 7000 loss: 0.37393662195542127\n",
      "  batch 8000 loss: 0.37523020038730465\n",
      "  batch 9000 loss: 0.3758150356612168\n",
      "  batch 10000 loss: 0.37038979804958216\n",
      "  batch 11000 loss: 0.3751827858254255\n",
      "  batch 12000 loss: 0.3760495946603478\n",
      "  batch 13000 loss: 0.3657687807586044\n",
      "  batch 14000 loss: 0.35376525543569004\n",
      "  batch 15000 loss: 0.33004335599954354\n",
      "LOSS train 0.33004335599954354 valid 0.34811320900917053\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.3343385476530821\n",
      "  batch 2000 loss: 0.3236038898298066\n",
      "  batch 3000 loss: 0.34597398631481335\n",
      "  batch 4000 loss: 0.33107398412404293\n",
      "  batch 5000 loss: 0.3183849456809985\n",
      "  batch 6000 loss: 0.31841804708342536\n",
      "  batch 7000 loss: 0.3129246370314795\n",
      "  batch 8000 loss: 0.312052442312317\n",
      "  batch 9000 loss: 0.31192346636456203\n",
      "  batch 10000 loss: 0.31611671871606084\n",
      "  batch 11000 loss: 0.32064293016179\n",
      "  batch 12000 loss: 0.3164572436521412\n",
      "  batch 13000 loss: 0.32744618396749137\n",
      "  batch 14000 loss: 0.31455822872037786\n",
      "  batch 15000 loss: 0.2895425899324073\n",
      "LOSS train 0.2895425899324073 valid 0.3373067080974579\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.29098057154382334\n",
      "  batch 2000 loss: 0.2964327549155278\n",
      "  batch 3000 loss: 0.3088784349139605\n",
      "  batch 4000 loss: 0.2936383176985455\n",
      "  batch 5000 loss: 0.28749619646351493\n",
      "  batch 6000 loss: 0.2903289951368861\n",
      "  batch 7000 loss: 0.2868692479483252\n",
      "  batch 8000 loss: 0.29049915624520506\n",
      "  batch 9000 loss: 0.2982395440453747\n",
      "  batch 10000 loss: 0.30043522356860924\n",
      "  batch 11000 loss: 0.2845499318744905\n",
      "  batch 12000 loss: 0.2864356147278595\n",
      "  batch 13000 loss: 0.2671870184178406\n",
      "  batch 14000 loss: 0.2995591901434091\n",
      "  batch 15000 loss: 0.30525614789268\n",
      "LOSS train 0.30525614789268 valid 0.3164908289909363\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.2658863176423183\n",
      "  batch 2000 loss: 0.27012788043802355\n",
      "  batch 3000 loss: 0.2523905169777136\n",
      "  batch 4000 loss: 0.27702347587865733\n",
      "  batch 5000 loss: 0.27169027287952485\n",
      "  batch 6000 loss: 0.27727677338772627\n",
      "  batch 7000 loss: 0.2728320064872678\n",
      "  batch 8000 loss: 0.274559533892133\n",
      "  batch 9000 loss: 0.2802412869596819\n",
      "  batch 10000 loss: 0.27159153514041645\n",
      "  batch 11000 loss: 0.2712830339340635\n",
      "  batch 12000 loss: 0.2745040271797952\n",
      "  batch 13000 loss: 0.27655362629916636\n",
      "  batch 14000 loss: 0.2839696086305812\n",
      "  batch 15000 loss: 0.27975131935438546\n",
      "LOSS train 0.27975131935438546 valid 0.3063870966434479\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
